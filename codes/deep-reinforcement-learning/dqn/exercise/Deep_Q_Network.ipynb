{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Network (DQN)\n",
    "---\n",
    "In this notebook, you will implement a DQN agent with OpenAI Gym's LunarLander-v2 environment.\n",
    "\n",
    "### 1. Import the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Instantiate the Environment and Agent\n",
    "\n",
    "Initialize the environment in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape:  (8,)\n",
      "Number of actions:  4\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "env.seed(0)\n",
    "print('State shape: ', env.observation_space.shape)\n",
    "print('Number of actions: ', env.action_space.n)\n",
    "\n",
    "# env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the next code cell, familiarize yourself with the code in **Step 2** and **Step 3** of this notebook, along with the code in `dqn_agent.py` and `model.py`.  Once you have an understanding of how the different files work together, \n",
    "- Define a neural network architecture in `model.py` that maps states to action values.  This file is mostly empty - it's up to you to define your own deep Q-network!\n",
    "- Finish the `learn` method in the `Agent` class in `dqn_agent.py`.  The sampled batch of experience tuples is already provided for you; you need only use the local and target Q-networks to compute the loss, before taking a step towards minimizing the loss.\n",
    "\n",
    "Once you have completed the code in `dqn_agent.py` and `model.py`, run the code cell below.  (_If you end up needing to make multiple changes and get unexpected behavior, please restart the kernel and run the cells from the beginning of the notebook!_)\n",
    "\n",
    "You can find the solution files, along with saved model weights for a trained agent, in the `solution/` folder.  (_Note that there are many ways to solve this exercise, and the \"solution\" is just one way of approaching the problem, to yield a trained agent._)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from model import QNetwork\n",
    "# qq = QNetwork(10,3,1)\n",
    "# # list(qq.parameters())\n",
    "# myoptimizer = torch.optim.Adam(qq.parameters(), lr=0.001)\n",
    "# myoptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class QNetwork(nn.Module):\n",
    "#     \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "#     def __init__(self, state_size, action_size, seed):\n",
    "#         \"\"\"Initialize parameters and build model.\n",
    "#         Params\n",
    "#         ======\n",
    "#             state_size (int): Dimension of each state\n",
    "#             action_size (int): Dimension of each action\n",
    "#             seed (int): Random seed\n",
    "#         \"\"\"\n",
    "#         super(QNetwork, self).__init__()\n",
    "#         self.seed = torch.manual_seed(seed)\n",
    "#         hidden_size = 64\n",
    "        \n",
    "#         self.model = nn.Sequential(\n",
    "#             nn.Linear(state_size, hidden_size),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(hidden_size, hidden_size),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(hidden_size, action_size),\n",
    "#         )\n",
    "        \n",
    "#         \"*** YOUR CODE HERE ***\"\n",
    "\n",
    "#     def forward(self, x): #x is state\n",
    "#         \"\"\"Build a network that maps state -> action values.\"\"\"\n",
    "#         x = self.model(x)\n",
    "        \n",
    "#         return x\n",
    "        \n",
    "qq = QNetwork(10,3,1)\n",
    "# list(qq.parameters())\n",
    "myoptimizer = torch.optim.Adam(qq.parameters(), lr=0.001)\n",
    "myoptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn_agent import Agent\n",
    "\n",
    "agent = Agent(state_size=8, action_size=4, seed=0)\n",
    "# help(Agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8adaee526826>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdqn_agent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# watch an untrained agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/hdd/Projects/bala/my-impl-of-deep-rl-nanodegree/codes/deep-reinforcement-learning/dqn/exercise/dqn_agent.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, state_size, action_size, seed)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnetwork_local\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnetwork_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnetwork_local\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Replay memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad)\u001b[0m\n\u001b[1;32m     39\u001b[0m         defaults = dict(lr=lr, betas=betas, eps=eps,\n\u001b[1;32m     40\u001b[0m                         weight_decay=weight_decay, amsgrad=amsgrad)\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mparam_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optimizer got an empty parameter list\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mparam_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "from dqn_agent import Agent\n",
    "\n",
    "agent = Agent(state_size=8, action_size=4, seed=0)\n",
    "\n",
    "# watch an untrained agent\n",
    "state = env.reset()\n",
    "for j in range(200):\n",
    "    action = agent.act(state)\n",
    "    #env.render()\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    if done:\n",
    "        break \n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the Agent with DQN\n",
    "\n",
    "Run the code cell below to train the agent from scratch.  You are welcome to amend the supplied values of the parameters in the function, to try to see if you can get better performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: -189.86\n",
      "Episode 200\tAverage Score: -143.54\n",
      "Episode 300\tAverage Score: -93.068\n",
      "Episode 400\tAverage Score: -28.43\n",
      "Episode 500\tAverage Score: -6.350\n",
      "Episode 600\tAverage Score: 115.92\n",
      "Episode 700\tAverage Score: 153.93\n",
      "Episode 800\tAverage Score: 119.33\n",
      "Episode 868\tAverage Score: 200.84\n",
      "Environment solved in 768 episodes!\tAverage Score: 200.84\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd64a74c400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dqn(n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=200.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            break\n",
    "    return scores\n",
    "\n",
    "scores = dqn()\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Watch a Smart Agent!\n",
    "\n",
    "In the next code cell, you will load the trained weights from file to watch a smart agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchDisplayException",
     "evalue": "Cannot connect to \"None\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchDisplayException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cdb5c13011f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVIEWPORT_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVIEWPORT_H\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Error occured while running `from pyglet.gl import *`\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HINT: make sure you have OpenGL install. On Ubuntu, you can run 'apt-get install python-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work: 'xvfb-run -s \\\"-screen 0 1400x900x24\\\" python <your_script.py>'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;31m# trickery is for circular import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0m_pyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyglet/window/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1894\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_pyglet_docgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1896\u001b[0;31m     \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_shadow_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m_create_shadow_window\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWindow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0m_shadow_window\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWindow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0m_shadow_window\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyglet/window/xlib/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_handlers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXlibWindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mglobal\u001b[0m \u001b[0m_can_detect_autorepeat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyglet/window/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, width, height, caption, resizable, style, fullscreen, visible, vsync, display, screen, config, context, mode)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             \u001b[0mdisplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_platform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyglet/window/__init__.py\u001b[0m in \u001b[0;36mget_default_display\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDisplay\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m         \"\"\"\n\u001b[0;32m-> 1845\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_pyglet_docgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyglet/canvas/__init__.py\u001b[0m in \u001b[0;36mget_display\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;31m# Otherwise, create a new display and return it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_pyglet_docgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyglet/canvas/xlib.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, x_screen)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXOpenDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNoSuchDisplayException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot connect to \"%s\"'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mscreen_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXScreenCount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchDisplayException\u001b[0m: Cannot connect to \"None\""
     ]
    }
   ],
   "source": [
    "# load the weights from file\n",
    "agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
    "\n",
    "for i in range(5):\n",
    "    state = env.reset()\n",
    "    for j in range(200):\n",
    "        action = agent.act(state)\n",
    "        env.render()\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        if done:\n",
    "            break \n",
    "            \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Explore\n",
    "\n",
    "In this exercise, you have implemented a DQN agent and demonstrated how to use it to solve an OpenAI Gym environment.  To continue your learning, you are encouraged to complete any (or all!) of the following tasks:\n",
    "- Amend the various hyperparameters and network architecture to see if you can get your agent to solve the environment faster.  Once you build intuition for the hyperparameters that work well with this environment, try solving a different OpenAI Gym task with discrete actions!\n",
    "- You may like to implement some improvements such as prioritized experience replay, Double DQN, or Dueling DQN! \n",
    "- Write a blog post explaining the intuition behind the DQN algorithm and demonstrating how to use it to solve an RL environment of your choosing.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
